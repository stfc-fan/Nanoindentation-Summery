{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5927130-e161-455b-81d0-e3df4f0760f1",
   "metadata": {},
   "source": [
    "## Extract and Summarize Nanoindentation Data\n",
    "\n",
    "This notebook is used for extraction of specified nanoindentation data from .xlsx files from the UKEA. The notebook will selectively extract data from a range of files, by taking only the data from a requested depth. Given a list of these requested depths, the code will take the datapoint closest to each depth. This will be done for each nanoindentation point in the data. This will yield a dataframe containing all load vs depth data relevant to these depths, which can either be used by the user for direct, analysis, or can also be recorded in a pre-prepared excel summary sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce09e0-0bc5-49d0-b81f-3713dd007c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import pylightxl as xl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7381a5ad-6f85-4818-9cb6-67dbd5c6a9a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Parameters:\n",
    "- **directory** = full path to folder containing all data files. The script will automatically recognise linescan files among others, as long as they follow the filename convention \"line_scan#.xlsx\" where # is an integer indicating linescan number (between 0-9). Path should prefarably be a [Raw String](https://docs.python.org/3/reference/lexical_analysis.html), especially if running on windows os. \n",
    "\n",
    "- **SUMMARY_FILE** = string path to summary file. \n",
    "\n",
    "- **DEPTHS** = list of all desired depths at which to get load data. The code will look to the closest value around each depth and extract the corresponding load value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd6dda-176c-4fa6-a5c2-102278e3dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory = r\"C:\\Users\\robya\\Documents\\SampleData\"\n",
    "SUMMARY_FILE = f\"C:\\\\Users\\\\robya\\\\Documents\\\\Summer Internship\\\\OneDrive_1_16-08-2022\\\\E97 Data set 1\\\\Time-resolved summary.xlsx\"\n",
    "DEPTHS = [200, 300]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fded6af4-dca5-4789-b110-94a605c010ff",
   "metadata": {},
   "source": [
    "#### Function Definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b9ef23-5943-4c1d-9dd2-c50729b665f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_array(file, depths=[200]):\n",
    "    \"\"\"\n",
    "    Produces a list of pandas dataframes containing load vs depth data for for all tests from a given file\n",
    "    IN: -file = string containing full file path, preferably a raw sting\n",
    "        -depths = list containing all desired depts at which to gain data.\n",
    "        -num_of_indentations = the amount of tests expected in the sheet. Default set to 40. If less are found, function will print a warning\n",
    "    OUT:-list of dataframes for each supplied depth\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_depth_load_data(file, depth):\n",
    "        \"\"\" Produce a dataframe of all loads within this linescan file at given depth\"\"\"\n",
    "        \n",
    "        depth_data = pd.DataFrame(columns = [\"Depth [nm]\", \"Load [mN]\"])\n",
    "        for num in range(1,100):   \n",
    "            \"\"\"Loops between all test numbers enclosed within the range object\"\"\"\n",
    "            try:\n",
    "                num = str(num).zfill(3)                                                        # padds the number with zeros so it is formated as \"0XX\" \n",
    "                data = pd.read_excel(file, sheet_name=f\"Test {num}\")\n",
    "                df = pd.to_numeric(data['Displacement Into Surface'][1:].sub(depth).abs())     # obtain the value closest to current selected depth NOTE: This is not the fastest way to do it\n",
    "                idx = df.idxmin()                                                              # index at which closest value occurs\n",
    "                datapoint = [data[\"Displacement Into Surface\"].iloc[idx], data[\"Load On Sample\"].iloc[idx]]# displacement and idx datapoint                              \n",
    "                depth_data = depth_data.append(pd.DataFrame([datapoint],  #append datapoint to depth_data \n",
    "                     columns=[\"Depth [nm]\", \"Load [mN]\"]), \n",
    "                     ignore_index=True)        \n",
    "\n",
    "            except ValueError:\n",
    "                print(f\"A total of {int(num)-1} Nanoindentation points were found @ depth of {depth}nm\")\n",
    "                print(\"_______________________________________________________________________________\")\n",
    "                break\n",
    "        depth_data.index += 1         #Begin index count at 1\n",
    "        return depth_data\n",
    "    \n",
    "    \n",
    "    listed_data = []\n",
    "    for depth in depths:\n",
    "        listed_data.append(get_depth_load_data(file, depth))\n",
    "    \n",
    "    print(f\"If you expect more, ensure that all sheets in file follow the format [Test XXX] \\n and that sequence of numbers is continuous and does not skip any said numbers\")\n",
    "    return listed_data\n",
    "    \n",
    "    \n",
    "def find_linescan_files(directory):\n",
    "    \"\"\"\n",
    "    Find all linescan files in input directory path\n",
    "    IN: -directory = string with directory name\n",
    "    OUT:-list with all linescan files in directory with full paths\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            files.append(os.path.splitext(file)[0])\n",
    "\n",
    "    files = fnmatch.filter(files, 'line_scan?') \n",
    "    new_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        file = os.path.join(directory,file+\".xlsx\")\n",
    "        new_files.append(file)\n",
    "\n",
    "    return new_files\n",
    "\n",
    "\n",
    "def gather_linescan_data(directory):\n",
    "    \"\"\"\n",
    "    Yields a dataframe containing all data from the linescans from UKEA\n",
    "    IN: -directory= string with full path to linescan files\n",
    "    OUT:-dataframe with data from all linescans in folder \n",
    "    \"\"\"\n",
    "    files = find_linescan_files(directory)\n",
    "    Linescans = [] \n",
    "    for file in files:\n",
    "        linescan_number = file[-6]           # The linescan number taken from filenames\n",
    "        print(f\"\\n\\n[Linescan {linescan_number} ]========================================================\")\n",
    "        data = get_test_array(file, DEPTHS)\n",
    "        data = pd.DataFrame([data], columns=DEPTHS, index=[linescan_number])\n",
    "        data.index.name = \"Linescan No.\"\n",
    "        Linescans.append(data)          \n",
    "    #print(Linescans)\n",
    "    data = pd.concat(Linescans)\n",
    "    return data\n",
    "\n",
    "\n",
    "def summarize_linescan(summary_file, full_data):\n",
    "    \"\"\"\n",
    "    Fill a summary file with data. Will write it into the excel sheet\n",
    "    IN: -summary_file= string of full path to summary file\n",
    "        -data= array with na-ion data for all depths as pd dataframes\n",
    "    OUT:-excel database ready to be saved as a file\n",
    "    \"\"\"\n",
    "    #READ DATABASE\n",
    "    db = xl.readxl(fn=summary_file)\n",
    "    for x in full_data.index:\n",
    "        current_sheet = f\"Linescan-{x}\"\n",
    "        data = full_data.loc[x]\n",
    "        data = [x for x in data]\n",
    "        \n",
    "        #Get the number of tests\n",
    "        num_of_tests = db.ws(ws=current_sheet).index(row=3, col=1)\n",
    "        for row_to_edit in range(3,num_of_tests+3):  \n",
    "            col_to_edit = 2\n",
    "               # for col_to_edit in range(2,4,2):\n",
    "            #Read index of first column,\n",
    "            current_idx = db.ws(ws=current_sheet).index(row=row_to_edit, col=1)\n",
    "\n",
    "            for datafr in data:\n",
    "                #Fetch index from dataframe\n",
    "                curr_value = datafr[\"Load [mN]\"].loc[current_idx]#[0]\n",
    "                #Write value from dataframe into database\n",
    "                db.ws(ws=current_sheet).update_index(row=+row_to_edit, col=col_to_edit, val=curr_value)\n",
    "                col_to_edit +=2\n",
    "\n",
    "    #Repeat for next indentation depth\n",
    "    #print(summary_file)\n",
    "    xl.writexl(db=db, fn=summary_file)\n",
    "    return db\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad326029-ac6f-45aa-8812-1c00fa329a1a",
   "metadata": {},
   "source": [
    "#### Main Cell\n",
    "Running this cell will execute the whole code. Note that the summarize_linescan function will only input. The \"Linescans\" variable will yield a DataFrame. Each cell houses data from a given linescan file (index of cell corresponding to the number of the linescan, and the column name of the cell corresponds to the depth at which the data was taken.\n",
    "\n",
    "\n",
    "\n",
    "![Image1](.\\Full_df.png).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Where each cell will house a dataframe containing depth vs load data. Each index corresponds to the indentation number, as specified in the linescan file.\n",
    "\n",
    "\n",
    "![Image2](.\\mini_df.png).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5581b72-cac1-4160-b235-a684c3827a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this line to get a dataframe containing all data from a dataset of xlsx files\n",
    "Linescans = gather_linescan_data(directory)\n",
    "\n",
    "# Run this line to input the data into a set SUMMARY_FILE. The output of this function will give you a database object \n",
    "# (from pylightxl) for analysis of the output to the summary file, without opening the excel itself\n",
    "_ = summarize_linescan(SUMMARY_FILE, Linescans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ef8c7-da60-43dc-8ad3-69b8866f4979",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "Note that the summarize_linescan function is not very smart. The user will need to prepare the summary file in an appropriate format. Each Linescan should have an appropriately named sheet using the format \"Linescan-#\", and should have the number of indentations expected. \n",
    "\n",
    "![Image3](.\\sum_sheet.png)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
